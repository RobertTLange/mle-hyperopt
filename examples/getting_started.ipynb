{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f9d077-64ed-4dc3-b772-498569e96d2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `mle-hyperopt`: Lightweight Hyperparameter Optimization\n",
    "### Author: [@RobertTLange](https://twitter.com/RobertTLange) [Last Update: October 2021][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/mle-logging/blob/main/examples/getting_started.ipynb)\n",
    "\n",
    "Validating a simulation across a large range of parameters or tuning the hyperparameters of a neural network is common practice for every computational scientist. There are many open source packages that implement individual algorithms, but many of them are either combersome to set up or follow different syntax. For my personal setup I wanted a simple API that allows me to generate batches of parameter configurations for various types of experiments and that comes with a set of handy utilities. These included the following: \n",
    "\n",
    "- **Simplicity and strategy diversity**: Most hyperparameter tools implement the newest population-based search/training algorithms and Bayesian Optimization variants, but often do not implement simple grid search. Yes, I know that [Bergstra and Bengio (2012)](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) showed that random search is more efficient, but my intuitive understanding as a scientiest is often more enhanced by semi-exhaustive evaluation.\n",
    "- **Interactive search space refinement**: After a certain set of search iterations, it can make sense to refine your search space boundaries based on the top performing configurations. This way we can focus on a smaller range of promising configurations. This was for example done in [Schmidt et al. (2021)](https://arxiv.org/abs/2007.01547) and significantly improve computation efficient resource allocation. \n",
    "- **Exporting of configuration files**: Often times I want to submit training runs to some large compute cluster (slurm, etc.) and need to execute a downstream training routine that looks somewhat as follows: `python train.py --config_fname config.yaml`. In that case it is useful to have one script that executes calls to the cluster scheduler after having generated the configurations.\n",
    "- **Storage and reloading of previous search logs**: I was astonished by how few libraries provide the simple utility of exporting and importing a previous search experiment for later continuation. E.g., in order to accomplish something similar in the FAIR's awesome [nevergrad](https://facebookresearch.github.io/nevergrad/) library, one has to write manual functionality that dumps the search log, reloads and supplies the previously stored results to a new search strategy instance.\n",
    "\n",
    "And this was how the `mle-hyperopt` package was born. [***Note***: I by no means claim that this is something novel. Most likely you may your own substitute tool. But maybe you find a couple of the package's features useful. So hang in there ðŸ¤—] As of writing the package includes a set of diverse (e.g. single vs. multi-objective, model-free vs. model-based) search algorithms:\n",
    "\n",
    "| Search Type           | Description | `search_config` |\n",
    "|----------------------- | ----------- | --------------- |\n",
    "|  `GridSearch`          |  Search over list of discrete values  | - |\n",
    "|  `RandomSearch`        |  Random search over variable ranges         | `refine_after`, `refine_top_k` |\n",
    "|  `SMBOSearch`          |  Sequential model-based optim.        | `base_estimator`, `acq_function`, `n_initial_points`\n",
    "|  `CoordinateSearch`    |  Coordinate-wise optim. with defaults | `order`, `defaults`\n",
    "|  `NevergradSearch`     |  Multi-objective [nevergrad](https://facebookresearch.github.io/nevergrad/) wrapper | `optimizer`, `budget_size`, `num_workers`\n",
    "\n",
    "Each strategy implements a separate search space which one can sample from. The API follows the standard `ask`, `eval`, `tell` paradigm and in the remainder of this 'blog notebook' we will walk through the different features and use-cases. Let's start by implementing a small 'synthetic' helper function that evaluates the performance of a combination of 3 standard hyperparameters -- learning rate, batchsize and architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ff5d35-b29e-4386-b423-9c83ad1ae169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "try:\n",
    "    import mle_hyperopt\n",
    "except:\n",
    "    !pip install -q mle-hyperopt\n",
    "    import mle_hyperopt\n",
    "\n",
    "def fake_train(lrate, batch_size, arch):\n",
    "    \"\"\"Optimum: lrate=0.2, batch_size=4, arch='conv'.\"\"\"\n",
    "    f1 = ((lrate - 0.2) ** 2 + ((batch_size - 4)/4) ** 2\n",
    "          + (0 if arch == \"conv\" else 0.2))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d6078-40a7-4715-89db-927b0e380025",
   "metadata": {},
   "source": [
    "## Basic API Usage: Grid Search Strategy\n",
    "\n",
    "Note that the API assumes that we are minimizing an objective. If you want to maximize simply multiply all objective values with minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7488b-34a3-47fc-837a-f088cfaa48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import GridSearch\n",
    "# Instantiate grid search class\n",
    "strategy = GridSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"bins\": 5}},\n",
    "                      integer={\"batch_size\": {\"begin\": 1,\n",
    "                                              \"end\": 5,\n",
    "                                              \"spacing\": 1}},\n",
    "                      categorical={\"arch\": [\"mlp\", \"cnn\"]},\n",
    "                      verbose=True)\n",
    "\n",
    "configs = strategy.ask(batch_size=2)\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985f7cd-8f04-4bb0-bb99-9030d4f339de",
   "metadata": {},
   "source": [
    "Next, we can evaluate our fake surrogate objective for the two proposal configurations and afterwards,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f6ced-c142-4a42-93d9-cc58246d14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ask - eval - tell API\n",
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69df333-f2d6-4479-b588-23966b459a9a",
   "metadata": {},
   "source": [
    "### Saving and reloading previous search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be549ca-4062-4a33-b40c-b0a7217bc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing of results to .pkl\n",
    "strategy.save(\"search_log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a0a3d-f8a0-4af2-9131-64ed6f08a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading of results from .pkl\n",
    "strategy.load(\"search_log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f83648-b46a-4ecd-9b6e-696a211d765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0309087-669c-41c6-b450-0275b6680459",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = GridSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"bins\": 5}},\n",
    "                      integer={\"batch_size\": {\"begin\": 1,\n",
    "                                              \"end\": 5,\n",
    "                                              \"spacing\": 1}},\n",
    "                      categorical={\"arch\": [\"mlp\", \"cnn\"]},\n",
    "                      reload_path=\"search_log.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae59ff3-7b18-47eb-bf34-18565db7e13b",
   "metadata": {},
   "source": [
    "### Inspecting the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64942eeb-4dae-403f-80f5-ad94ea902344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return flattened log as pandas dataframe\n",
    "strategy.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6a1ef-fcdc-404a-b161-77d77242229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the best performing configuration\n",
    "strategy.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7490e4d-bf23-491e-a603-229b6a52add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot timeseries of best performing score over search iterations\n",
    "strategy.plot_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7495374-6249-4db8-930c-86ed6d664b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out ranking of best performers\n",
    "strategy.print_ranking(top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a9690-f708-4c15-847c-73a9b2be6abc",
   "metadata": {},
   "source": [
    "### Adding fixed parameters & storing configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312aece-7a41-4ada-84e2-c0c79497af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = GridSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"bins\": 5}},\n",
    "                      integer={\"batch_size\": {\"begin\": 1,\n",
    "                                              \"end\": 5,\n",
    "                                              \"spacing\": 1}},\n",
    "                      categorical={\"arch\": [\"mlp\", \"cnn\"]},\n",
    "                      fixed_params={\"momentum\": 0.9})\n",
    "strategy.ask(2, store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861c990-2497-44a7-a956-a44be45eadc6",
   "metadata": {},
   "source": [
    "## Single-Objective: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c2fa2-2941-49ca-9f34-49b9a0e53b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import RandomSearch\n",
    "\n",
    "strategy = RandomSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                        \"end\": 0.5,\n",
    "                                        \"prior\": \"uniform\"}},\n",
    "                        integer={\"batch_size\": {\"begin\": 1,\n",
    "                                                \"end\": 5,\n",
    "                                                \"prior\": \"log-uniform\"}},\n",
    "                        categorical={\"arch\": [\"mlp\", \"cnn\"]},\n",
    "                        search_config={\"refine_after\": 5,\n",
    "                                       \"refine_top_k\": 2},\n",
    "                        seed_id=42,\n",
    "                        verbose=True)\n",
    "\n",
    "configs = strategy.ask(5)\n",
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beaab87-b7b1-4548-9f37-8d57b820c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.get_best(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2f77d-2848-4af0-8e9d-ff645c076b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.print_ranking(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149a725-3223-473e-85ac-956b5e343518",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = RandomSearch(\n",
    "        real={\"lrate\": {\"begin\": 0.1, \"end\": 0.5, \"prior\": \"uniform\"}},\n",
    "        integer={\"batch_size\": {\"begin\": 1, \"end\": 5, \"prior\": \"uniform\"}},\n",
    "        categorical={\"arch\": [\"mlp\", \"cnn\"]},\n",
    "    )\n",
    "configs = strategy.ask(5)\n",
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)\n",
    "strategy.get_best(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff0d18-988b-4b57-a74e-0191e1834b4b",
   "metadata": {},
   "source": [
    "## Single-Objective: Sequential Model-Based Optimization (SMBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b435e-5141-4389-a0ae-4de9f1d60f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import SMBOSearch\n",
    "\n",
    "strategy = SMBOSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"prior\": \"uniform\"}},\n",
    "                      integer={\"batch_size\": {\"begin\": 1,\n",
    "                                              \"end\": 5,\n",
    "                                              \"prior\": \"uniform\"}},\n",
    "                      search_config={\"base_estimator\": \"GP\",\n",
    "                                     \"acq_function\": \"gp_hedge\",\n",
    "                                     \"n_initial_points\": 5},\n",
    "                      fixed_params={\"arch\": \"cnn\"})\n",
    "\n",
    "configs = strategy.ask(5)\n",
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602f43c-c190-4fd0-a45b-6d80cfa4fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.print_ranking(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f28a40-32f2-4662-8e39-801019a5a03e",
   "metadata": {},
   "source": [
    "## Multi-Objective: `nevergrad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd69fd1-76bf-44ed-9025-fb4302d0bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import NevergradSearch\n",
    "\n",
    "strategy = NevergradSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"prior\": \"uniform\"}},\n",
    "                           integer={\"batch_size\": {\"begin\": 1,\n",
    "                                                   \"end\": 5,\n",
    "                                                   \"prior\": \"uniform\"}},\n",
    "                           search_config={\"optimizer\": \"NGOpt\",\n",
    "                                          \"budget_size\": 100,\n",
    "                                          \"num_workers\": 5},\n",
    "                           fixed_params={\"arch\": \"cnn\"})\n",
    "\n",
    "configs = strategy.ask(5)\n",
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)\n",
    "strategy.print_ranking(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b4e98-0c67-4478-bae7-207203378831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_fake_train(lrate, batch_size, arch):\n",
    "    # optimal for learning_rate=0.2, batch_size=4, architecture=\"conv\"\n",
    "    f1 = ((lrate - 0.2) ** 2 + (batch_size - 4) ** 2\n",
    "          + (0 if arch == \"conv\" else 10))\n",
    "    # optimal for learning_rate=0.3, batch_size=2, architecture=\"mlp\"\n",
    "    f2 = ((lrate - 0.3) ** 2 + (batch_size - 2) ** 2\n",
    "          + (0 if arch == \"mlp\" else 5))\n",
    "    return f1, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28631203-c216-4f71-aa58-038c83c7db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = NevergradSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                      \"end\": 0.5,\n",
    "                                      \"prior\": \"uniform\"}},\n",
    "                           integer={\"batch_size\": {\"begin\": 1,\n",
    "                                                   \"end\": 5,\n",
    "                                                   \"prior\": \"uniform\"}},\n",
    "                           search_config={\"optimizer\": \"NGOpt\",\n",
    "                                          \"budget_size\": 100,\n",
    "                                          \"num_workers\": 5},\n",
    "                           fixed_params={\"arch\": \"cnn\"})\n",
    "\n",
    "configs = strategy.ask(5)\n",
    "values = [multi_fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)\n",
    "strategy.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018e5ad-4e9c-4291-841e-2da05d1222a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.print_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a07dae-cc95-4ad0-af14-f30a672a12c0",
   "metadata": {},
   "source": [
    "## Coordinate-Wise Search\n",
    "\n",
    "Start scanning one parameter for fixed others and a fixed budget. Afterwards, fix the optimized parameter to best value and go over to next parameter. Repeat until all parameters are done. `search_config` specifies order of parameters and their default. Internally, we run a coordinate-wise grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078c46b-71b7-4891-93c6-56651ede3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import CoordinateSearch\n",
    "strategy = CoordinateSearch(real={\"lrate\": {\"begin\": 0.1,\n",
    "                                            \"end\": 0.5,\n",
    "                                            \"bins\": 5}},\n",
    "                            integer={\"batch_size\": {\"begin\": 1,\n",
    "                                                    \"end\": 5,\n",
    "                                                    \"spacing\": 1}},\n",
    "                            search_config={\"order\": [\"lrate\", \"batch_size\"],\n",
    "                                           \"defaults\": {\"lrate\": 0.1,\n",
    "                                                        \"batch_size\": 3}},\n",
    "                            fixed_params={\"arch\": \"cnn\"})\n",
    "\n",
    "configs = strategy.ask(5)\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191113d-debe-401f-b1a7-45b9a6626364",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)\n",
    "strategy.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e37cf-d2c2-42e9-8b86-71c335596849",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = strategy.ask(4)\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca18908-7845-4809-9e29-84a3bddd4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [fake_train(**c) for c in configs]\n",
    "strategy.tell(configs, values)\n",
    "strategy.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6a15b-2384-440b-b4d6-d0f87670acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.all_evaluated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a5267-ce18-4bc7-b426-814b0c36729f",
   "metadata": {},
   "source": [
    "# `hyperopt` decorator - minimal search wrapper\n",
    "\n",
    "Note: Assumes that function to evaluate directly consumes a configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fefb1-63e2-43f9-a7b8-dcb56fc7ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_hyperopt import hyperopt\n",
    "\n",
    "@hyperopt(strategy_type=\"grid\",\n",
    "          num_search_iters=400,\n",
    "          real={\"x\": {\"begin\": -0.5, \"end\": 0.5, \"bins\": 20},\n",
    "                \"y\": {\"begin\": -0.5, \"end\": 0.5, \"bins\": 20}})\n",
    "def circle_objective(config):\n",
    "    distance = abs((config[\"x\"] ** 2 + config[\"y\"] ** 2))\n",
    "    return distance\n",
    "\n",
    "strategy = circle_objective()\n",
    "len(strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4b727-21b6-4b80-9b59-2ccb37e58695",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.plot_grid(params_to_plot=[\"x\", \"y\"],\n",
    "                   target_to_plot=\"objective\",\n",
    "                   plot_title=\"Circles for Life\",\n",
    "                   plot_subtitle=\"How beautiful can they be?\",\n",
    "                   xy_labels= [\"x\", \"y\"],\n",
    "                   variable_name=\"Objective\",\n",
    "                   every_nth_tick=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508c44b-474a-44f4-a389-c0864b214118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ab830-5caf-4bde-82bf-dbc637d4171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c32c6c-f4c5-4890-85fb-97630f67b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mle-toolbox)",
   "language": "python",
   "name": "mle-toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
